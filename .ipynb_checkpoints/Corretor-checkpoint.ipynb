{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22de8ccf",
   "metadata": {},
   "source": [
    "# Correto Ortográfico em Python: Aplicando técnicas de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8673bca",
   "metadata": {},
   "source": [
    "## Importando um corpus textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fc383ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo um arquivo(corpus) de texto\n",
    "with open('corretor-master/artigos.txt', 'r', encoding='utf-8') as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4d8bdc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# Visualisando os primeiros 500 caracteres\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36e40b",
   "metadata": {},
   "source": [
    "> Observamos que onde contem trechos com imagens e códigos em nosso arquivo, são substituídos pela palavra \"imagem\" e \"java\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f2f54",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6f3d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "# Para entender melhor\n",
    "texto_exemplo = 'Olá, tudo bem?'\n",
    "palavras_separadas = texto_exemplo.split()\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b708e51",
   "metadata": {},
   "source": [
    "> o método .split() particionou nossa frase, porém existe um detalhe, ele separoou a vírgula junto na primeira palavra 'Olá,' e o sinal de interrogação na última 'bem?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8032604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Printando o tamando da lista\n",
    "print(len(palavras_separadas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3f8b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "# Alterando o nome dá variavel palavras separadas\n",
    "tokens = palavras_separadas\n",
    "print(len(tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fe8346",
   "metadata": {},
   "source": [
    "## Refinando a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "017fda1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71a5ccdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4183cd",
   "metadata": {},
   "source": [
    "> Já observamos que agora a separação está correta, porém, não queremos pegar as pontuações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a61c78d",
   "metadata": {},
   "source": [
    "## Separando palavras de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4abe6452",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a quantidade de palavras dentro de palavras_separadas\n",
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "60c371ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função para separar as palavras das pontuações\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for i in lista_tokens:\n",
    "        if i.isalpha():\n",
    "            lista_palavras.append(i)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad60677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a função\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77b3e85",
   "metadata": {},
   "source": [
    "> A função funcionou perfeitamente eliminando as pontuações que constam na lista de palavras separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85337721",
   "metadata": {},
   "source": [
    "## Contando palavras do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c9330db6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras dentro de nossa lista de palavras é: 403104\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f'O número de palavras dentro de nossa lista de palavras é: {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1034c3",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d6c55c",
   "metadata": {},
   "source": [
    "<p>Pegando apenas as palavras únicas detro da nossa lista</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecfc6daf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'Temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as 5 primeiras palavras\n",
    "lista_palavras[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330a81ae",
   "metadata": {},
   "source": [
    "> A palavra 'Temos' tem uma letra maiúscula, se tiver outro exemplo como 'temos' com letra minúscula, será contabilizado como duas palavras, sendo que são a mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57ed6557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de normalizar nossa lista\n",
    "def normalizacao(lista):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "45afca88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "# Atribuindo a função a uma variável\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda245fb",
   "metadata": {},
   "source": [
    "> Agora todas as palavras estão em letras minúsculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846834ae",
   "metadata": {},
   "source": [
    "## Tipos de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f01588c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicando o função set() que retorna um conjunto matemático, sendo assim, eliminando as palavras repetidas da lista\n",
    "lista_normalizada = set(lista_normalizada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "05803e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando novamente a quantidade de palavras da lista\n",
    "len(lista_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642b8e7e",
   "metadata": {},
   "source": [
    "> Agora com a normalização da lista, temos uma quantidade bem menor de palavras, 18465, bem diferente das 403104 que tinha antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e2b738",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
