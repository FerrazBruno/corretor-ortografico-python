{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ababa316",
   "metadata": {},
   "source": [
    "# Correto Ortográfico em Python: Aplicando técnicas de NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28916335",
   "metadata": {},
   "source": [
    "## Importando um corpus textual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc383ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lendo um arquivo(corpus) de texto\n",
    "with open('corretor-master/artigos.txt', 'r', encoding='utf-8') as f:\n",
    "    artigos = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d8bdc09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# Visualisando os primeiros 500 caracteres\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36e40b",
   "metadata": {},
   "source": [
    "> Observamos que onde contem trechos com imagens e códigos em nosso arquivo, são substituídos pela palavra \"imagem\" e \"java\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b19c634",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6f3d2c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "# Para entender melhor\n",
    "texto_exemplo = 'Olá, tudo bem?'\n",
    "palavras_separadas = texto_exemplo.split()\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b708e51",
   "metadata": {},
   "source": [
    "> o método .split() particionou nossa frase, porém existe um detalhe, ele separoou a vírgula junto na primeira palavra 'Olá,' e o sinal de interrogação na última 'bem?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8032604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "# Printando o tamando da lista\n",
    "print(len(palavras_separadas))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3f8b588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "['Olá,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "# Alterando o nome dá variavel palavras separadas\n",
    "tokens = palavras_separadas\n",
    "print(len(tokens))\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650504a2",
   "metadata": {},
   "source": [
    "## Refinando a tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "017fda1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/bruno/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Natural Language Toolkit\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eef35be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', ',', 'tudo', 'bem', '?']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando\n",
    "palavras_separadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c2d5eb",
   "metadata": {},
   "source": [
    "> Já observamos que agora a separação está correta, porém, não queremos pegar as pontuações."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8887aa",
   "metadata": {},
   "source": [
    "## Separando palavras de tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "203bd80d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verificando a quantidade de palavras dentro de palavras_separadas\n",
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6a8aa17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma função para separar as palavras das pontuações\n",
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for i in lista_tokens:\n",
    "        if i.isalpha():\n",
    "            lista_palavras.append(i)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1d9749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Olá', 'tudo', 'bem']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testando a função\n",
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f9cd81",
   "metadata": {},
   "source": [
    "> A função funcionou perfeitamente eliminando as pontuações que constam na lista de palavras separadas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddf12c7",
   "metadata": {},
   "source": [
    "## Contando palavras do Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81183105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras dentro de nossa lista de palavras é: 403104\n"
     ]
    }
   ],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)\n",
    "print(f'O número de palavras dentro de nossa lista de palavras é: {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279c1fbf",
   "metadata": {},
   "source": [
    "## Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22cdee0e",
   "metadata": {},
   "source": [
    "<p>Pegando apenas as palavras únicas detro da nossa lista</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef103e7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem', 'Temos', 'a', 'seguinte', 'classe']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizando as 5 primeiras palavras\n",
    "lista_palavras[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e05ee9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403104"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_palavras)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a82447bc",
   "metadata": {},
   "source": [
    "> A palavra 'Temos' tem uma letra maiúscula, se tiver outro exemplo como 'temos' com letra minúscula, será contabilizado como duas palavras, sendo que são a mesma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e469973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função de normalizar nossa lista\n",
    "def normalizacao(lista):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f7af766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', 'java', 'para', 'salvar', 'um', 'novo', 'usuário', 'várias', 'validações', 'são', 'feitas', 'como', 'por', 'exemplo', 'ver', 'se', 'o', 'nome', 'só', 'contém', 'letras', 'o', 'cpf', 'só', 'números', 'e', 'ver', 'se', 'o', 'usuário', 'possui', 'no', 'mínimo', 'anos', 'veja', 'o', 'método', 'que', 'faz', 'essa', 'validação', 'java', 'suponha', 'agora', 'que', 'eu', 'tenha', 'outra', 'classe', 'a', 'classe', 'produto', 'que', 'contém', 'um', 'atributo', 'nome', 'e', 'eu', 'quero', 'fazer', 'a', 'mesma', 'validação', 'que', 'fiz', 'para', 'o', 'nome', 'do', 'usuário', 'ver', 'se', 'só', 'contém', 'letras', 'e', 'aí', 'vou', 'criar', 'outro', 'método', 'para', 'fazer', 'a', 'mesma', 'validação', 'ou', 'criar', 'uma', 'interface', 'ou', 'uma', 'classe', 'que', 'tanto', 'usuario', 'quanto', 'produto', 'estendem', 'não', 'faz', 'muito', 'sentido', 'né', 'como', 'resolver', 'esse', 'caso', 'sem', 'repetir', 'código', 'anotações', 'no', 'java', 'um', 'novo', 'recurso', 'foi', 'introduzido', 'à', 'linguagem', 'as', 'anotações', 'elas', 'permitem', 'que', 'metadados', 'sejam', 'escritos', 'diretamente', 'no', 'código', 'metadados', 'são', 'por', 'definição', 'dados', 'que', 'fazem', 'referência', 'aos', 'próprios', 'dados', 'para', 'nos', 'ajudar', 'a', 'entender', 'o', 'conceito', 'de', 'metadados', 'vou', 'usar', 'a', 'definição', 'feita', 'pelo', 'autor', 'eduardo', 'guerra', 'no', 'livro', 'componentes', 'reutilizáveis', 'em', 'java', 'com', 'reflexão', 'e', 'anotações', 'contexto', 'da', 'orientação', 'a', 'objetos', 'os', 'metadados', 'são', 'informações', 'sobre', 'do', 'código', 'essas', 'informações', 'podem', 'ser', 'definidas', 'em', 'qualquer', 'meio', 'que', 'o', 'software', 'ou', 'componente', 'as', 'recupere', 'e', 'as', 'utilize', 'para', 'agregar', 'nos', 'elementos', 'do', 'código', 'perceba', 'que', 'por', 'si', 'só', 'anotações', 'não', 'fazem', 'nada', 'elas', 'precisam', 'que', 'a', 'aplicação', 'as', 'recupere', 'e', 'as', 'utilize', 'para', 'que', 'só', 'assim', 'elas', 'consigam', 'nos', 'fornecer', 'algo', 'que', 'possamos', 'usar', 'para', 'realizar', 'alguma', 'tarefa', 'voltando', 'ao', 'nosso', 'problema', 'vamos', 'criar', 'uma', 'anotação', 'para', 'validar', 'a', 'idade', 'mínina', 'do', 'usuário', 'para', 'isso', 'vamos', 'anotar', 'nossa', 'classe', 'java', 'se', 'olharmos', 'nosso', 'código', 'perceberemos', 'que', 'ele', 'não', 'compila', 'pois', 'falta', 'implementarmos', 'a', 'anotação', 'idademinina', 'logo', 'precisamos', 'criar', 'uma', 'nova', 'classe', 'com', 'o', 'nome', 'idademinima', 'java', 'mas', 'pensando', 'bem', 'estamos', 'criando', 'uma', 'classe', 'não', 'estamos', 'portanto', 'a', 'nomenclatura', 'é', 'diferente', 'para', 'uma', 'anotação', 'a', 'forma', 'correta', 'seria', 'java', 'estranho', 'né', 'mas', 'foi', 'o', 'jeito', 'que', 'o', 'pessoal', 'do', 'java', 'fez', 'para', 'falar', 'que', 'esse', 'arquivo', 'se', 'trata', 'de', 'uma', 'anotação', 'agora', 'temos', 'que', 'anotar', 'nossa', 'interface', 'com', 'algumas', 'anotações', 'obrigatórias', 'para', 'que', 'o', 'java', 'entenda', 'onde', 'e', 'quando', 'sua', 'anotação', 'pode', 'ser', 'utilizada', 'sendo', 'elas', 'retention', 'aqui', 'nós', 'falaremos', 'para', 'a', 'nossa', 'aplicação', 'até', 'quando', 'nossa', 'anotação', 'estará', 'disponível', 'target', 'aqui', 'passaremos', 'os', 'elementos', 'que', 'podem', 'ser', 'anotados', 'com', 'essa', 'anotação', 'até', 'onde', 'nossa', 'anotação', 'estará', 'disponível', 'precisamos', 'que', 'ela', 'seja', 'executada', 'quando', 'o', 'usuário', 'enviar', 'os', 'seus', 'dados', 'e', 'isso', 'acontece', 'quando', 'nossa', 'aplicação', 'está', 'rodando', 'logo', 'precisamos', 'dela', 'em', 'tempo', 'de', 'execução', 'java', 'e', 'quem', 'será', 'anotado', 'que', 'elemento', 'faz', 'sentido', 'ser', 'anotado', 'com', 'uma', 'anotação', 'que', 'verifica', 'se', 'o', 'usuário', 'tem', 'idade', 'suficiente', 'um', 'atributo', 'certo', 'logo', 'um', 'java', 'agora', 'que', 'já', 'especificamos', 'o', 'contexto', 'da', 'nossa', 'anotação', 'precisamos', 'falar', 'qual', 'a', 'idade', 'mínima', 'que', 'a', 'nossa', 'anotação', 'deve', 'usar', 'para', 'validar', 'a', 'idade', 'do', 'usuário', 'para', 'isso', 'vamos', 'criar', 'uma', 'propriedade', 'na', 'nossa', 'anotação', 'chamada', 'valor', 'java', 'nossa', 'anotação', 'está']\n"
     ]
    }
   ],
   "source": [
    "# Atribuindo a função a uma variável\n",
    "lista_normalizada = normalizacao(lista_palavras)\n",
    "print(lista_normalizada[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f424b1f0",
   "metadata": {},
   "source": [
    "> Agora todas as palavras estão em letras minúsculas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49eabb1a",
   "metadata": {},
   "source": [
    "## Tipos de palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4853274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando o função set() que retorna um conjunto matemático, sendo assim, eliminando as palavras repetidas da lista\n",
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee74be9",
   "metadata": {},
   "source": [
    "> Agora com a normalização da lista, temos uma quantidade bem menor de palavras, 18465, bem diferente das 403104 que tinha antes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f317b2f",
   "metadata": {},
   "source": [
    "## Fatiando as strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93a0792a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Operação de inserção\n",
    "def insere_letras(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "    for E, D in fatias: # as fatias serão uma lista de tuplas com 2 valores dentro [('l', 'gica')]\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)\n",
    "    return novas_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "074a9a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "palavra_exemplo = 'lgica'\n",
    "def gerador_de_palavras(palavra):\n",
    "    fatias= []\n",
    "    for i in range(len(palavra)+1): # +1 para ir além da última letra\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2cdef0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "palavras_geradas = gerador_de_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319898d4",
   "metadata": {},
   "source": [
    "## Construindo a função corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5944c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a função que retorna a palavra correta\n",
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_de_palavras(palavra)\n",
    "    palavras_correta = max(palavras_geradas, key=probabilidade)\n",
    "    return palavras_correta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9719d096",
   "metadata": {},
   "source": [
    "## Probabilidade das palavras geradas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d545c0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb56de66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00023815194093831864"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada] / total_palavras\n",
    "\n",
    "probabilidade('lógica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3dee68f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor(palavra_exemplo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27919f4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
